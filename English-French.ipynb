{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "from tqdm import tqdm_notebook\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_sequence, pad_packed_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "Batch = namedtuple(\"Batch\", [\"text\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c5eaea0cc74922818f24ca5846bb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=170652), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### Partie traduction\n",
    "\n",
    "PAD = 0\n",
    "EOS = 1\n",
    "SOS = 2\n",
    "\n",
    "class VocabularyTrad:\n",
    "    def __init__(self):\n",
    "        self.word2id = {\"<PAD>\":PAD,\"<EOS>\":EOS,\"<SOS>\":SOS}\n",
    "        self.id2word = {PAD:\"<PAD>\",EOS:\"<EOS>\",SOS:\"<SOS>\"}\n",
    "    \n",
    "    def get_sentence(self,sentence):\n",
    "        return [self.get(x,True) for x in sentence.split(\" \")]+[1]\n",
    "    def get(self,w,adding=False):\n",
    "        try:\n",
    "            return self.word2id[w]\n",
    "        except KeyError:\n",
    "            if adding:\n",
    "                self.word2id[w]=len(self.word2id)\n",
    "                self.id2word[self.word2id[w]]=w\n",
    "                return self.word2id[w]\n",
    "            raise\n",
    "    def __getitem__(self,i): return self.id2word[i]\n",
    "    def __len__(self): return len(self.word2id)\n",
    "\n",
    "\n",
    "def normalize(s):\n",
    "    return ''.join(c if c in string.ascii_letters else \" \"\n",
    "         for c in unicodedata.normalize('NFD', s.lower().strip()) \n",
    "         if  c in string.ascii_letters+\" \"+string.punctuation)\n",
    "\n",
    "\n",
    "\n",
    "class TradDataset():\n",
    "    def __init__(self,data,vocOrig,vocDest,adding=True,max_len=10):\n",
    "        self.sentences =[]\n",
    "        for s in tqdm_notebook(data.split(\"\\n\")):\n",
    "            if len(s)<1:continue\n",
    "            orig,dest=map(normalize,s.split(\"\\t\")[:2])\n",
    "            if len(orig)>max_len: continue            \n",
    "            self.sentences.append((torch.tensor(vocOrig.get_sentence(orig)),torch.tensor(vocDest.get_sentence(dest))))\n",
    "    def __len__(self):return len(self.sentences)\n",
    "    def __getitem__(self,i): return self.sentences[i]\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate(batch):\n",
    "        data = [torch.Tensor(item[0].float()).long() for item in batch]\n",
    "        labels = [torch.Tensor(item[1].float()).long() for item in batch]\n",
    "        \n",
    "        #return Batch(pack_sequence(data, enforce_sorted=True), pack_sequence(labels, enforce_sorted=True))\n",
    "        return Batch(data, labels)\n",
    "\n",
    "\n",
    "with open(\"fra-eng/fra.txt\") as f:\n",
    "    lines = f.read()\n",
    "vocEng = VocabularyTrad()\n",
    "vocFra = VocabularyTrad()\n",
    "datatrain = TradDataset(lines,vocEng,vocFra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, orig_vocab_size, embed_size, hidden_size, n_layers=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.orig_vocab_size = orig_vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(orig_vocab_size, embed_size)\n",
    "        self.encode = nn.LSTM(embed_size, hidden_size, n_layers, bidirectional=False, batch_first=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        embeds = self.embedding_layer(X)\n",
    "        outsEncoder, (hidden, cell) = self.encode(pack_sequence(embeds))\n",
    "        \n",
    "        \"\"\"In case we have more than one layer lstm or bidirectional one\"\"\"\n",
    "        context = hidden.transpose(0,1).contiguous().view(hidden.size(1),1,-1)\n",
    "        cell = cell.transpose(0,1).contiguous().view(cell.size(1),1,-1)\n",
    "        \n",
    "        return context,cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dest_vocab_size, embed_size, hidden_size, n_layers=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.dest_vocab_size = dest_vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(dest_vocab_size, embed_size)\n",
    "        self.decoder_one_step = nn.LSTM(embed_size, hidden_size,n_layers, bidirectional=False, batch_first=True)\n",
    "        self.project = nn.Linear(n_layers*hidden_size, dest_vocab_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, X, h_c_tuple):\n",
    "        \"\"\"X.size(): batch*1\"\"\"\n",
    "        h,c=h_c_tuple\n",
    "        X=X.unsqueeze(1)\n",
    "        embed = self.embedding_layer(X)\n",
    "        #print(\"***\",h.shape, c.shape)\n",
    "        outputs, (hidden, cell) = self.decoder_one_step(embed,(h,c))\n",
    "        #print(hidden.shape)\n",
    "        y_hat = self.project(hidden)\n",
    "        #print(y_hat.shape)\n",
    "        return y_hat, (hidden.transpose(0,1), cell.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, X_src, X_target, constrained_mode_prob=0.3, train=True):\n",
    "        \n",
    "        #pdb.set_trace()\n",
    "        #print(len(X))\n",
    "        #pdb.set_trace()\n",
    "        X_src=pad_sequence(X_src, batch_first=True, padding_value=PAD).long()\n",
    "        X_target=pad_sequence(X_target, batch_first=False, padding_value=PAD).long()\n",
    "        \n",
    "        trg_len = X_target.size(0) \n",
    "        \"\"\"Batch size\"\"\"\n",
    "        hiddens,cells = self.encoder(X_src)    \n",
    "        \n",
    "        batch_size = hiddens.size(0)\n",
    "        \"\"\"Decoder\"\"\"\n",
    "        \n",
    "        #print(\":::::\",hiddens.shape, cells.shape)\n",
    "        \n",
    "        X = torch.Tensor([SOS]*batch_size).long()\n",
    "        \n",
    "        if train:\n",
    "            \n",
    "            outputs = torch.zeros(trg_len, batch_size, self.decoder.dest_vocab_size)\n",
    "            for i in range(trg_len):\n",
    "                X, (hiddens, cells) = self.decoder(X,(hiddens.transpose(0,1),cells.transpose(0,1)))\n",
    "\n",
    "                outputs[i]=X.squeeze(0)\n",
    "\n",
    "                constraint = random.random() < constrained_mode_prob\n",
    "                if constraint:\n",
    "                    X = X_target[i]\n",
    "                else:\n",
    "                    X = X.argmax(2).squeeze(0)\n",
    "        else:\n",
    "            i=0\n",
    "            outputs=[]\n",
    "            while X.item()!=EOS:\n",
    "                \n",
    "                X, (hiddens, cells) = self.decoder(X,(hiddens.transpose(0,1),cells.transpose(0,1)))\n",
    "\n",
    "                outputs.append(X.squeeze(0))\n",
    "                X = X.argmax(2).squeeze(0)\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,808,725 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "\n",
    "embed_size_encoder=256\n",
    "embed_size_decoder=256\n",
    "\n",
    "hidden_dim_encoder=512\n",
    "\n",
    "hidden_dim_decoder=hidden_dim_encoder\n",
    "\n",
    "orig_vocab_size=len(vocEng.word2id)\n",
    "dest_vocab_size=len(vocFra.word2id)\n",
    "\n",
    "dataLoaderTrain = DataLoader(datatrain, batch_size=batch_size, collate_fn=datatrain.collate)\n",
    "\n",
    "encoderModel = Encoder(orig_vocab_size, embed_size_encoder, hidden_dim_encoder, n_layers=1)\n",
    "decoderModel = Decoder(dest_vocab_size, embed_size_decoder,hidden_dim_decoder, n_layers=1)\n",
    "seq2seqModel = Seq2Seq(encoderModel, decoderModel)\n",
    "\n",
    "lr=0.0001\n",
    "optimizer = optim.Adam(list(seq2seqModel.parameters())+list(encoderModel.parameters())+list(decoderModel.parameters()),lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "nb_epoch = 300\n",
    "clip = 1\n",
    "\n",
    "constrained_mode_prob = 0.9\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(seq2seqModel):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e58f93b96c14b8d82fea07cc9285054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_errors = []\n",
    "for epoch in tqdm_notebook(range(nb_epoch)):\n",
    "    epoch_error = 0\n",
    "    for x,y in dataLoaderTrain:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs=seq2seqModel(x,y, constrained_mode_prob=0.8, train=True)\n",
    "        \n",
    "        y=pad_sequence(y).view(-1)\n",
    "        outputs=outputs.view(-1,outputs.shape[-1])\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        list_errors.append(loss.item())\n",
    "        #torch.nn.utils.clip_grad_norm_(seq2seqModel.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_error+=loss.item()\n",
    "        if epoch%10 == 0:\n",
    "            constrained_mode_prob*=constrained_mode_prob\n",
    "        \n",
    "    #print(epoch_error/len(dataLoaderTrain))\n",
    "    #list_errors.append(epoch_error/len(dataLoaderTrain))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f928983d9b0>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seqModel=seq2seqModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "see\n",
      "\n",
      "<EOS>\n",
      "je\n",
      "comprends\n",
      "\n",
      "<EOS>\n"
     ]
    }
   ],
   "source": [
    "x,y=datatrain.__getitem__(20)\n",
    "for word in x:\n",
    "    print(vocEng.id2word[word.item()])\n",
    "\n",
    "for word in y:\n",
    "    print(vocFra.id2word[word.item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, sentence, vocOri, vocDest):\n",
    "    #pdb.set_trace()\n",
    "    sentence_ids = torch.Tensor(vocOri.get_sentence(sentence)).long().unsqueeze(0)\n",
    "    y_hat = model(sentence_ids,sentence_ids, 0, False)\n",
    "    \n",
    "    sentence_target = \"\"\n",
    "    for word in y_hat:\n",
    "        sentence_target+=vocDest.id2word[word.argmax(1).item()]+\" \"\n",
    "    print(\"Sentence origin:{}\\nSentence target:{}\".format(sentence, sentence_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence origin:who is he\n",
      "Sentence target:qui est il  <EOS> \n"
     ]
    }
   ],
   "source": [
    "sentence = \"who is he\"\n",
    "translate(seq2seqModel, sentence, vocEng, vocFra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq2seqModel.state_dict(), \"./modelEngFra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
